{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES에 deal_word2vec 인덱스 생성\n",
    "\n",
    "- 환경: ElasticSearch \n",
    "- 머신: twiceSpark1\n",
    "- 개요\n",
    "    - deal 마다 word2vec 정보를 저장하는 인덱스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "PUT /deal_word2vec\n",
    "{\n",
    "    \"mappings\": {\n",
    "    \"doc\": {\n",
    "      \"properties\": {\n",
    "        \"v\": {\"type\":\"long\"},\n",
    "        \"words\": {\"type\":\"keyword\"},\n",
    "        \"values\": {\"type\":\"double\"}\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import json\n",
    "import elasticsearch\n",
    "import csv\n",
    "import pickle\n",
    "from elasticsearch.helpers import bulk\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "from datetime import timezone, timedelta, datetime\n",
    "from pymongo import MongoClient\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_documents(file_path):\n",
    "    pred_dic = {}\n",
    "    with open(file_path, 'rb') as jsonfile:\n",
    "        for row in jsonfile:\n",
    "            source_ = eval(row)\n",
    "            source = {}\n",
    "            source['v'] = source_['v']\n",
    "            source['words'] = source_['words']\n",
    "            source['values'] = source_['vectorizedWords']['values']\n",
    "            doc =  {\n",
    "                \"_op_type\":'create',\n",
    "                \"_index\":\"deal_word2vec\",\n",
    "                \"_type\":\"doc\",\n",
    "                \"_id\": source['v'],\n",
    "                \"_source\": source\n",
    "            }\n",
    "            yield(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### twiceSpark1: 10.102.50.47\n",
    "es_url = 'twiceSpark1:9200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es = elasticsearch.Elasticsearch(es_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "es.indices.get_mapping(index='deal_word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bulk inserting to ES\n",
    "\n",
    "인덱스: 'deal_word2vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = r'd:\\WMIND\\temp\\word2vec.json'\n",
    "start = time.time()\n",
    "total_time = 0\n",
    "bulk(es, make_documents(data_dir), request_timeout=20)\n",
    "total_time += (time.time() - start)\n",
    "print(\"Elapsed Time {} sec\".format(total_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
